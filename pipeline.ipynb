{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(\"cellcycle\", nan_strategy=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from hiclass import MultiLabelLocalClassifierPerNode\n",
    "from hiclass.metrics import make_leveled, precision, recall, f1\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from feature_selection import ModSelectKBest\n",
    "from handle_nan import NumericImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", NumericImputer(strategy=\"mean\")),\n",
    "    (\"selector\", ModSelectKBest(k=10)),\n",
    "    (\"model\", MultiLabelLocalClassifierPerNode(DecisionTreeClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\venv\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ModSelectKBest was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\venv\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ModSelectKBest was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(d.x_train(expand=True), d.y_train(expand=True))\n",
    "y_pred = pipeline.predict(d.x_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_y_pred = make_leveled(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [[11, 02, 01], [11, 02, 02], [11, 02, 03, 01]]\n",
       "1                                          [[12, 04, 02]]\n",
       "2       [[01, 04], [14, 01], [14, 04], [16, 01], [16, ...\n",
       "3              [[10, 03, 02], [42, 10], [43, 01, 03, 09]]\n",
       "4                            [[10, 01, 05, 01], [32, 01]]\n",
       "                              ...                        \n",
       "1623                                   [[11, 02, 03, 04]]\n",
       "1624    [[16, 19, 03], [20, 01, 27], [20, 03, 22], [32...\n",
       "1625                 [[11, 02, 03, 01], [11, 02, 03, 04]]\n",
       "1626                 [[32, 05, 01, 03, 03], [32, 07, 03]]\n",
       "1627                               [[20, 01, 01, 01, 01]]\n",
       "Name: class, Length: 1628, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = d.y_train(expand=False)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y_true \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39my_test()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mf1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfill_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\venv\\lib\\site-packages\\hiclass\\metrics.py:232\u001b[0m, in \u001b[0;36mf1\u001b[1;34m(y_true, y_pred, average)\u001b[0m\n\u001b[0;32m    227\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m _validate_input(y_true, y_pred)\n\u001b[0;32m    228\u001b[0m functions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m: _f_score_micro,\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m: _f_score_macro,\n\u001b[0;32m    231\u001b[0m }\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctions\u001b[49m\u001b[43m[\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\venv\\lib\\site-packages\\hiclass\\metrics.py:242\u001b[0m, in \u001b[0;36m_f_score_macro\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_f_score_macro\u001b[39m(y_true: np\u001b[38;5;241m.\u001b[39mndarray, y_pred: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_macro\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_f_score_micro\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\venv\\lib\\site-packages\\hiclass\\metrics.py:248\u001b[0m, in \u001b[0;36m_compute_macro\u001b[1;34m(y_true, y_pred, _micro_function)\u001b[0m\n\u001b[0;32m    246\u001b[0m overall_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ground_truth, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(y_true, y_pred):\n\u001b[1;32m--> 248\u001b[0m     sample_score \u001b[38;5;241m=\u001b[39m \u001b[43m_micro_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m     overall_sum \u001b[38;5;241m=\u001b[39m overall_sum \u001b[38;5;241m+\u001b[39m sample_score\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m overall_sum \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true)\n",
      "File \u001b[1;32mc:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\venv\\lib\\site-packages\\hiclass\\metrics.py:238\u001b[0m, in \u001b[0;36m_f_score_micro\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    236\u001b[0m prec \u001b[38;5;241m=\u001b[39m precision(y_true, y_pred)\n\u001b[0;32m    237\u001b[0m rec \u001b[38;5;241m=\u001b[39m recall(y_true, y_pred)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "y_true = d.y_test()\n",
    "f1(fill_reshape(y_true), y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1281, 13, 6)\n",
      "(1281, 14, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\feature_selection.py:75: FutureWarning: The provided callable <built-in function max> is currently using Series.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  max_len = y.apply(len).agg(max)\n",
      "c:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\feature_selection.py:76: FutureWarning: The provided callable <built-in function max> is currently using Series.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  depth = y.apply(lambda x: max([len(label) for label in x])).agg(max)\n"
     ]
    }
   ],
   "source": [
    "print(fill_reshape(y_true).shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Retriever' 'Golden Retriever']\n",
      "  ['Hound' 'Dachshund']]\n",
      "\n",
      " [['Retriever' 'Labrador']\n",
      "  ['' '']]\n",
      "\n",
      " [['Hound' 'Dachshund']\n",
      "  ['Hound' 'Beagle']]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from hiclass.MultiLabelLocalClassifierPerNode import MultiLabelLocalClassifierPerNode\n",
    "\n",
    "# Define data\n",
    "X_train = [[1, 2], [3, 4], [5, 6]]\n",
    "X_test = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "# Define Labels\n",
    "Y_train = np.array([\n",
    "    [[\"Retriever\", \"Golden Retriever\"], [\"Hound\", \"Dachshund\"]],\n",
    "    [[\"Retriever\", \"Labrador\"]],\n",
    "    [[\"Hound\", \"Dachshund\"], [\"Hound\", \"Beagle\"]],\n",
    "], dtype=object)\n",
    "\n",
    "# Use decision tree classifiers for every node\n",
    "tree = DecisionTreeClassifier()\n",
    "classifier = MultiLabelLocalClassifierPerNode(local_classifier=tree)\n",
    "\n",
    "# Train local classifier per node\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\feature_selection.py:75: FutureWarning: The provided callable <built-in function max> is currently using Series.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  max_len = y.apply(len).agg(max)\n",
      "c:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\feature_selection.py:76: FutureWarning: The provided callable <built-in function max> is currently using Series.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  depth = y.apply(lambda x: max([len(label) for label in x])).agg(max)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feature_selection import fill_reshape\n",
    "\n",
    "f1(fill_reshape(pd.Series(Y_train)), predictions, average=\"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
