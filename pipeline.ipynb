{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(\"cellcycle\", nan_strategy=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Literal\n",
    "from feature_selection import ModSelectKBest, IterativeSelect\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from hiclass import MultiLabelLocalClassifierPerNode\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "FeatureSelector = Union[ModSelectKBest, IterativeSelect]\n",
    "# Can't be imported for some reason\n",
    "ImputerStrategy = Union[Literal[\"drop\"],\n",
    "                        Literal[\"knn\"],\n",
    "                        Literal[\"mean\"],\n",
    "                        Literal[\"median\"],\n",
    "                        Literal[\"most_frequent\"],\n",
    "                        Literal[\"constant\"]]\n",
    "\n",
    "IMPUTER_STRATEGY = \"mean\"\n",
    "IMPUTER_KWARGS = {}\n",
    "MODEL_STEPS = [\n",
    "    # (\"model\", MultiLabelLocalClassifierPerNode(DecisionTreeClassifier())),\n",
    "    (\"model\", MultiLabelLocalClassifierPerNode(\n",
    "        local_classifier=LogisticRegression(\n",
    "            penalty='l2',\n",
    "            C=0.01,\n",
    "            solver='lbfgs',\n",
    "            max_iter=10000\n",
    "        )\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Optional, Tuple, Any\n",
    "\n",
    "from feature_selection import fill_reshape\n",
    "from handle_nan import NumericImputer\n",
    "\n",
    "\n",
    "def prep_dataset(dataset: Dataset,\n",
    "                 imputer_strategy: ImputerStrategy,\n",
    "                 imputer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                 x_train_prep: Optional[Callable[[pd.DataFrame], pd.DataFrame]] = None,\n",
    "                 ) -> Tuple[Dict[str, pd.DataFrame],\n",
    "                            NumericImputer]:\n",
    "    imputer = NumericImputer(strategy=imputer_strategy, **(imputer_kwargs or {}))\n",
    "    data: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    data[\"x_train\"] = dataset.x_train()\n",
    "    if x_train_prep is not None:\n",
    "        data[\"x_train\"] = x_train_prep(data[\"x_train\"])\n",
    "    data[\"y_train\"] = dataset.y_train()\n",
    "    imputer.fit(data[\"x_train\"], data[\"y_train\"])\n",
    "\n",
    "    data[\"x_valid\"] = dataset.x_valid()\n",
    "    data[\"y_valid\"] = dataset.y_valid()\n",
    "    data[\"x_valid\"] = imputer.transform(data[\"x_valid\"])\n",
    "    \n",
    "    data[\"x_test\"] = dataset.x_test()\n",
    "    data[\"y_test\"] = dataset.y_test()\n",
    "    data[\"y_test_reshaped\"] = fill_reshape(data[\"y_test\"])\n",
    "    return data, imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hiclass.metrics import f1\n",
    "from handle_nan import NumericImputer\n",
    "from feature_selection import fill_reshape\n",
    "\n",
    "def evaluate(dataset: Optional[Dataset] = None,\n",
    "             data: Optional[Dict[str, pd.DataFrame]] = None,\n",
    "             model_steps: List[Tuple[str, BaseEstimator]] = [],\n",
    "             imputer_strategy: ImputerStrategy = \"mean\",\n",
    "             imputer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "             x_train_prep: Optional[Callable[[pd.DataFrame], pd.DataFrame]] = None,\n",
    "             name: str = \"baseline\",\n",
    "             verbose: bool = False):\n",
    "    if data is None:\n",
    "        if dataset is None:\n",
    "            raise ValueError(\"Either dataset or data must be provided\")\n",
    "        data, imputer = prep_dataset(dataset,\n",
    "                                     imputer_strategy,\n",
    "                                     imputer_kwargs,\n",
    "                                     x_train_prep)\n",
    "    else:\n",
    "        imputer = NumericImputer(strategy=imputer_strategy, **(imputer_kwargs or {}))\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"imputer\", imputer),\n",
    "        *model_steps,\n",
    "    ], verbose=verbose, memory=\"cache\")\n",
    "    \n",
    "    pipeline.fit(data[\"x_train\"], data[\"y_train\"])\n",
    "    y_pred = pipeline.predict(data[\"x_test\"])\n",
    "    score = f1(data[\"y_test_reshaped\"], fill_reshape(y_pred))\n",
    "    if verbose:\n",
    "        print(f\"{name}: {score}\", flush=True)\n",
    "    return name, score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 1.3min\n",
      "baseline: 0.4073478144274604\n",
      "baseline  : 0.4073\n"
     ]
    }
   ],
   "source": [
    "base_name, base_f1_score = evaluate(\n",
    "    dataset=d,\n",
    "    model_steps=MODEL_STEPS,\n",
    "    imputer_strategy=\"mean\",\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"{base_name:<10}: {base_f1_score:.4f}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Iterable, Optional\n",
    "from feature_selection import ModSelectKBest, IterativeSelect\n",
    "from itertools import product\n",
    "from pprint import PrettyPrinter\n",
    "\n",
    "\n",
    "pp = PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "def feature_selection(dataset: Dataset,\n",
    "                      model_steps: List[Tuple[str, BaseEstimator]],\n",
    "                      imputer_strategy: ImputerStrategy,\n",
    "                      imputer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                      n_feature_splits: Optional[int] = None,\n",
    "                      n_features: Optional[Iterable[int]] = None,\n",
    "                      n_epochs: int | Iterable[int] = 100,\n",
    "                      verbose: bool = False):\n",
    "    data, _ = prep_dataset(dataset, imputer_strategy, imputer_kwargs)\n",
    "    train_n_features = data[\"x_train\"].shape[1]\n",
    "    \n",
    "    if n_features is None:\n",
    "        if n_feature_splits is None:\n",
    "            n_feature_splits = 5\n",
    "\n",
    "        n_features = [round(k * train_n_features / (n_feature_splits + 1))\n",
    "                      for k\n",
    "                      in range(1, n_feature_splits + 1)]\n",
    "    elif any(not (0 < k <= train_n_features) for k in n_features):\n",
    "            raise ValueError(\"Invalid number of features\")\n",
    "    \n",
    "    if isinstance(n_epochs, int):\n",
    "        n_epochs = [n_epochs]\n",
    "    \n",
    "    selectors = (\n",
    "        (\"k_best\",\n",
    "         [{\"k\": k} for k in n_features]),\n",
    "        (\"iterative\",\n",
    "         [\n",
    "             {\n",
    "                 \"k\": k,\n",
    "                 \"x_valid\": data[\"x_valid\"],\n",
    "                 \"y_valid\": data[\"y_valid\"],\n",
    "                 \"epochs\": epochs,\n",
    "                 \"verbose\": verbose,\n",
    "             }\n",
    "             for k, epochs\n",
    "             in product(n_features, n_epochs)\n",
    "         ])\n",
    "    )\n",
    "    \n",
    "    for key, kwargs in selectors:\n",
    "        for kw in kwargs:\n",
    "            selector = ModSelectKBest(**kw) if key == \"k_best\" else IterativeSelect(**kw)\n",
    "            \n",
    "            name, score = evaluate(\n",
    "                data=data,\n",
    "                model_steps=[(\"selector\", selector), *model_steps],\n",
    "                imputer_strategy=imputer_strategy,\n",
    "                imputer_kwargs=imputer_kwargs,\n",
    "                name=f\"{key}_{kw.get('k', 'X')}\",\n",
    "                verbose=verbose\n",
    "            )\n",
    "            yield name, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline        : 0.4582\n",
      "k_best_38       : 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sjtom\\Documents\\MUNI\\Semester jar 2024\\PV056 - Machine Learning and Data Mining\\hiclass\\venv\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but IterativeSelect was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterative_38    : 0.4602\n"
     ]
    }
   ],
   "source": [
    "feat_sel_results = feature_selection(d,\n",
    "                                     MODEL_STEPS,\n",
    "                                     imputer_strategy=IMPUTER_STRATEGY,\n",
    "                                     imputer_kwargs=IMPUTER_KWARGS,\n",
    "                                     n_feature_splits=1,\n",
    "                                     n_epochs=1,\n",
    "                                     verbose=False)\n",
    "\n",
    "print(f\"{base_name:<16}: {base_f1_score:.4f}\", flush=True)\n",
    "for sel_name, f1_score in feat_sel_results:\n",
    "    print(f\"{sel_name:<16}: {f1_score:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from hiclass.MultiLabelLocalClassifierPerNode import MultiLabelLocalClassifierPerNode\n",
    "from hiclass.metrics import f1\n",
    "from feature_selection import fill_reshape\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def add_noise_to_train(train_df, percentage):\n",
    "    noisy_train = train_df.copy()\n",
    "    numeric_columns = train_df.select_dtypes(include=[np.number]).columns\n",
    "    noise = (train_df[numeric_columns].max() - train_df[numeric_columns].min()) * (percentage / 100)\n",
    "    noisy_train[numeric_columns] += noise\n",
    "    return noisy_train\n",
    "\n",
    "class NoisePreprocessor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, scaling_method='standard', outlier_method='zscore', outlier_threshold=3.0):\n",
    "        self.scaling_method = scaling_method\n",
    "        self.outlier_method = outlier_method\n",
    "        self.outlier_threshold = outlier_threshold\n",
    "        self.scaler_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.outlier_method in ['zscore', 'iqr', 'clip', 'mean']:\n",
    "            X_clean, _ = self._remove_outliers(X, y)\n",
    "        else:\n",
    "            X_clean = X\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "\n",
    "        if self.outlier_method in ['zscore', 'iqr', 'clip', 'mean']:\n",
    "            X, y = self._remove_outliers(X, y)\n",
    "        \n",
    "        if y is not None:\n",
    "            return X, y\n",
    "        return X\n",
    "\n",
    "    def _remove_outliers(self, df, y=None):\n",
    "        if self.outlier_method == 'zscore':\n",
    "            return self._remove_outliers_zscore(df, y)\n",
    "        elif self.outlier_method == 'iqr':\n",
    "            return self._remove_outliers_iqr(df, y)\n",
    "        elif self.outlier_method == 'clip':\n",
    "            return self._clip_outliers(df, y)\n",
    "        elif self.outlier_method == 'mean':\n",
    "            return self._replace_outliers_with_mean(df, y)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown outlier method: {self.outlier_method}\")\n",
    "\n",
    "    def _remove_outliers_zscore(self, df, y=None):\n",
    "        numeric_cols = df.select_dtypes(include=[np.number])\n",
    "        z_scores = np.abs(stats.zscore(numeric_cols))\n",
    "        filtered_entries = (z_scores < self.outlier_threshold).all(axis=1)\n",
    "        if y is not None:\n",
    "            return df.loc[filtered_entries], y.loc[filtered_entries]\n",
    "        return df.loc[filtered_entries], y\n",
    "\n",
    "    def _remove_outliers_iqr(self, df, y=None):\n",
    "        Q1 = df.quantile(0.25)\n",
    "        Q3 = df.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        filter = (df >= (Q1 - 1.5 * IQR)) & (df <= (Q3 + 1.5 * IQR))\n",
    "        filtered_entries = filter.all(axis=1)\n",
    "        if y is not None:\n",
    "            return df.loc[filtered_entries], y.loc[filtered_entries]\n",
    "        return df.loc[filtered_entries], y\n",
    "\n",
    "    def _clip_outliers(self, df, y=None, lower_percentile=0.01, upper_percentile=0.99):\n",
    "        lower_bound = df.quantile(lower_percentile)\n",
    "        upper_bound = df.quantile(upper_percentile)\n",
    "        df_clipped = df.clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
    "        return df_clipped, y\n",
    "\n",
    "    def _replace_outliers_with_mean(self, df, y=None):\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            outliers = np.abs((df[col] - mean) / std) > self.outlier_threshold\n",
    "            df.loc[outliers, col] = mean\n",
    "        return df, y\n",
    "\n",
    "    def _scale_data(self, df):\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        df.loc[:, numeric_cols] = self.scaler_.transform(df[numeric_cols])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_data(dataset: Dataset,\n",
    "                      model_steps: List[Tuple[str, BaseEstimator]],\n",
    "                      imputer_strategy: ImputerStrategy,\n",
    "                      imputer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                      verbose: bool = False):\n",
    "    for i in range(-10, 11):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        data, _ = prep_dataset(\n",
    "                    dataset,\n",
    "                    imputer_strategy,\n",
    "                    imputer_kwargs,\n",
    "                    x_train_prep=lambda x: add_noise_to_train(x, percentage=i)\n",
    "                )\n",
    "        \n",
    "        args = [\n",
    "            {'outlier_method': 'mean',\n",
    "             'outlier_threshold': 3.0,\n",
    "             'scaling_method': None\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for kw in args:\n",
    "            preprocessor = NoisePreprocessor(**kw)\n",
    "            \n",
    "            name, score = evaluate(\n",
    "                data=data,\n",
    "                model_steps=[(\"preprocessor\", preprocessor), *model_steps],\n",
    "                imputer_strategy=imputer_strategy,\n",
    "                imputer_kwargs=imputer_kwargs,\n",
    "                name=f\"numeric {i}%\",\n",
    "                verbose=verbose\n",
    "            )\n",
    "            yield name, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline        : 0.4073\n",
      "numeric -10%    : 0.3602\n",
      "numeric -9%     : 0.3630\n",
      "numeric -8%     : 0.3649\n",
      "numeric -7%     : 0.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_sel_results = noisy_data(d,\n",
    "                             MODEL_STEPS,\n",
    "                             imputer_strategy=IMPUTER_STRATEGY,\n",
    "                             imputer_kwargs=IMPUTER_KWARGS,\n",
    "                             verbose=False)\n",
    "\n",
    "print(f\"{base_name:<16}: {base_f1_score:.4f}\", flush=True)\n",
    "for sel_name, f1_score in feat_sel_results:\n",
    "    print(f\"{sel_name:<16}: {f1_score:.4f}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
